{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad600be3-3373-4507-8701-71479b8bfe14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypdf\n",
    "import pytesseract\n",
    "import requests\n",
    "import io\n",
    "\n",
    "import openai\n",
    "import tiktoken\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4295e9a8-687b-4d6d-82e2-ba700330c1c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# step 1: PDF -> Text\n",
    "def get_pdf(url:str) -> io.BytesIO:\n",
    "    pdf_response = requests.get(pdf_url)\n",
    "    pdf_bytes = io.BytesIO(pdf_response.content) # to avoid storing it locally\n",
    "    return pdf_bytes\n",
    "\n",
    "def extract_text(pdf_bytes: io.BytesIO) -> str:\n",
    "    # Step 2: Extract text from the PDF file\n",
    "    pdf_reader = pypdf.PdfReader(pdf_bytes)\n",
    "    ocr_text = \"\"\n",
    "    for page in range(len(pdf_reader.pages)):\n",
    "        page_obj = pdf_reader.pages[page]\n",
    "        ocr_text += page_obj.extract_text()\n",
    "    return ocr_text\n",
    "\n",
    "def ocrize_pdf(url: str) -> str:\n",
    "    pdf_bytes = get_pdf(url)\n",
    "    return extract_text(pdf_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b420788-1202-4457-9839-582600eb2b95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.85 s ± 698 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "pdf_url = \"https://arxiv.org/pdf/2304.03843.pdf\"\n",
    "%timeit pdf_text = ocrize_pdf(pdf_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89ddb201-5e02-4659-8c5f-03588a265980",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why think step-by-step? Reasoning emerges from the\n",
      "locality of experience\n",
      "Ben Prystawski\n",
      "Department \n"
     ]
    }
   ],
   "source": [
    "pdf_text = ocrize_pdf(pdf_url)\n",
    "print(pdf_text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ec7d0a-56fc-4b95-8f2b-c43236d31fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2: Summarize test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8badc14-0421-47f6-823b-aa0dac7e6a62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# preliminary step - assess cost before calling API\n",
    "def compute_num_tokens(text, encoder_type : str = \"cl100k_base\") -> int:\n",
    "    token_encoder = tiktoken.get_encoding(encoder_type)\n",
    "    num_tokens = len(token_encoder.encode(text))\n",
    "    return num_tokens\n",
    "\n",
    "# TODO - parse automatically open ai page? \"https://openai.com/pricing\"\n",
    "token_price_per_model = {# more recent models\n",
    "                         \"gpt-4\": 0.03, \n",
    "                         \"gpt-4-32k\": 0.06,\n",
    "                         \"gpt-3.5-turbo\":0.002, \n",
    "                         \"text-embedding-ada-002\": 0.0004,\n",
    "                         # older gpt-3 models\n",
    "                         \"text-ada-001\": 0.0004,\n",
    "                         \"text-babbage-001\": 0.0005,\n",
    "                         \"text-curie-001\": 0.002,\n",
    "                         \"text-davinci-003\": 0.02}\n",
    "\n",
    "model_context_length = {\"gpt-4\": 8196, \n",
    "                        \"gpt-4-32k\": 32768, \n",
    "                        \"gpt-3.5-turbo\": 4096, \n",
    "                        \"text-davinci-003\":4097, \n",
    "                        \"text-embedding-ada-002\": 8191}\n",
    "\n",
    "def compute_api_call_price(num_input_tokens, model_params:dict) -> float:\n",
    "    max_total_tokens = num_input_tokens + model_params[\"max_tokens\"]\n",
    "    max_price = max_total_tokens * token_price_per_model[model_params[\"model\"]]\n",
    "    return max_price/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f858cdc-5ba8-4453-b043-1f8b9e1de9af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def summarize_text(input_text:str, model_params:dict) -> str:\n",
    "    messages = [\n",
    "    #   {\"role\": \"system\", \"content\": \"Summarize the following article\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Summarize the following text in less than 10 sentences: \\n {input_text}\"}\n",
    "    ]\n",
    "    content_input = \" \".join([message[\"content\"] for message in messages])\n",
    "    num_input_tokens = compute_num_tokens(content_input)\n",
    "    max_total_tokens = num_input_tokens + model_params[\"max_tokens\"]\n",
    "    max_context_length = model_context_length[model_params[\"model\"]]\n",
    "    if max_total_tokens > max_context_length:\n",
    "        print(f\"Input longer than model max context length ({max_total_tokens}>{max_context_length}). Operation cancelled\")\n",
    "        return \"\"\n",
    "        # TODO - Add logic to shorten messages up to 4097 tokens\n",
    "    print(f\"The input text contains {num_input_tokens} tokens.\")\n",
    "    max_price = compute_api_call_price(num_input_tokens, model_params)\n",
    "    is_continue = input(f\"The api call can cost up to {max_price}$. Continue? [y/n]\")\n",
    "    if is_continue == \"y\":        \n",
    "        summary = openai.ChatCompletion.create(\n",
    "          messages = messages,\n",
    "          **model_params\n",
    "        )\n",
    "        return summary\n",
    "    else:\n",
    "        print(\"Operation cancelled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7d3c863-da31-4cb7-829f-a0b9ce44a25f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_params = {\"model\": \"gpt-3.5-turbo\", \n",
    "                \"max_tokens\":200, \n",
    "                \"temperature\":0.7,\n",
    "                \"top_p\":1.0, # default value\n",
    "                \"frequency_penalty\": 0.0, \n",
    "                \"presence_penalty\":0.5,\n",
    "                \"stop\" : \"\",\n",
    "                \"stream\": False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2784fc83-831f-4909-b41d-f11991d39e52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shorten_pdf_text = pdf_text[:17000]\n",
    "len(shorten_pdf_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "996a6041-e570-4161-b8fb-8a89513f79ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input text contains 3699 tokens.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "The api call can cost up to 0.07798$. Continue? [y/n] y\n"
     ]
    }
   ],
   "source": [
    "pdf_summary = summarize_text(shorten_pdf_text, model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4be190d4-d6e1-4d31-9666-368ac9f8a380",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The article explores the hypothesis that reasoning is effective when training data consists of local clusters of variables that have strong influences on each other. The authors use language models to investigate this question and find that intermediate reasoning steps only help when the training data has a locality structure that corresponds to the variables that strongly influence each other. They also find that generating variables that d-separate the observed variable from the target variable is useful for improving conditional inference while generating irrelevant variables is not. The article discusses the methods used to generate the training data and the estimators used to estimate the conditional probabilities. The results show that chain-of-thought reasoning improves estimation because it can chain together local statistical dependencies that are frequently observed in training. The article concludes that the statistical structure of training data drives the effectiveness of reasoning step by step.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_summary[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f661097b-5db3-49c5-b588-ff2e4be6f8c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
